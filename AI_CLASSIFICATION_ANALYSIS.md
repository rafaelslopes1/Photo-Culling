# AnÃ¡lise e Proposta de Sistema de ClassificaÃ§Ã£o com IA

## ğŸ“Š AnÃ¡lise dos Dados Atuais

### Dados Coletados no Sistema Atual

**âœ… Pontos Fortes:**
- **RÃ³tulos de Qualidade**: Escala 1-5 (â­ a â­â­â­â­â­)
- **Categorias de RejeiÃ§Ã£o**: blur, dark, light, cropped, other
- **Metadados Temporais**: timestamps, session_id
- **Banco de Dados Estruturado**: SQLite com backup JSON

**ğŸ“ˆ DistribuiÃ§Ã£o Atual dos Dados:**
```
Total de Imagens Rotuladas: 23
â”œâ”€â”€ Qualidade (15 imagens):
â”‚   â”œâ”€â”€ Score 2: 1 imagem (6.7%)
â”‚   â”œâ”€â”€ Score 4: 7 imagens (46.7%)
â”‚   â””â”€â”€ Score 5: 7 imagens (46.7%)
â””â”€â”€ Rejeitadas (8 imagens):
    â”œâ”€â”€ Blur: 6 imagens (75%)
    â”œâ”€â”€ Cropped: 1 imagem (12.5%)
    â””â”€â”€ Dark: 1 imagem (12.5%)
```

### ğŸ” AnÃ¡lise dos Dados para IA

**âœ… Dados Suficientes para ComeÃ§ar:**
1. **Classes bem definidas** (qualidade 1-5 + categorias de rejeiÃ§Ã£o)
2. **Estrutura de dados consistente**
3. **Interface de rotulagem eficiente**

**âŒ LimitaÃ§Ãµes Identificadas:**
1. **Volume de dados insuficiente** (23 amostras vs. milhares necessÃ¡rias)
2. **Desbalanceamento de classes** (ausÃªncia de scores 1 e 3)
3. **Falta de features automÃ¡ticas** (metadados de imagem, features visuais)
4. **AusÃªncia de validaÃ§Ã£o cruzada**
5. **Falta de dados de contexto** (EXIF, dimensÃµes, formato)

## ğŸ¯ Proposta de Sistema de IA Robusto

### Fase 1: Coleta e Enriquecimento de Dados (2-4 semanas)

#### 1.1 ExpansÃ£o do Dataset
- **Meta**: 1000+ imagens rotuladas por classe
- **EstratÃ©gia**: Rotulagem ativa com sugestÃµes de IA
- **Prioridade**: Balanceamento das classes (especialmente scores 1 e 3)

#### 1.2 ExtraÃ§Ã£o AutomÃ¡tica de Features
```python
Features Propostas:
â”œâ”€â”€ Metadados EXIF
â”‚   â”œâ”€â”€ Camera, ISO, Exposure, F-stop
â”‚   â”œâ”€â”€ DimensÃµes, Formato, Tamanho do arquivo
â”‚   â””â”€â”€ Data/hora, GPS (se disponÃ­vel)
â”œâ”€â”€ Features Visuais
â”‚   â”œâ”€â”€ Histogramas RGB/HSV
â”‚   â”œâ”€â”€ Texturas (LBP, GLCM)
â”‚   â”œâ”€â”€ Sharpness/Blur metrics
â”‚   â”œâ”€â”€ Exposure/Brightness metrics
â”‚   â””â”€â”€ ComposiÃ§Ã£o (rule of thirds, symmetry)
â”œâ”€â”€ Features Deep Learning
â”‚   â”œâ”€â”€ Embeddings de CNNs prÃ©-treinadas
â”‚   â”œâ”€â”€ Features de objetos detectados
â”‚   â””â”€â”€ Features estÃ©ticas (NIMA, AVA)
â””â”€â”€ Features de Contexto
    â”œâ”€â”€ Similaridade com outras imagens
    â”œâ”€â”€ AnÃ¡lise de faces/pessoas
    â””â”€â”€ AnÃ¡lise de cenÃ¡rio (indoor/outdoor)
```

### Fase 2: Modelo de IA Multi-Modal (4-6 semanas)

#### 2.1 Arquitetura Proposta
```
Sistema HÃ­brido:
â”œâ”€â”€ MÃ³dulo 1: Feature Engineering ClÃ¡ssico
â”‚   â”œâ”€â”€ Random Forest para features numÃ©ricas
â”‚   â”œâ”€â”€ SVM para features de textura
â”‚   â””â”€â”€ Ensemble de algoritmos tradicionais
â”œâ”€â”€ MÃ³dulo 2: Deep Learning
â”‚   â”œâ”€â”€ CNN prÃ©-treinada (EfficientNet/ResNet)
â”‚   â”œâ”€â”€ Transfer Learning com fine-tuning
â”‚   â””â”€â”€ Multi-task learning (qualidade + defeitos)
â””â”€â”€ MÃ³dulo 3: Fusion Layer
    â”œâ”€â”€ Meta-learner para combinar prediÃ§Ãµes
    â”œâ”€â”€ Confidence scoring
    â””â”€â”€ Active learning para casos incertos
```

#### 2.2 Pipeline de Treinamento
1. **PrÃ©-processamento**: NormalizaÃ§Ã£o, augmentation, balanceamento
2. **Feature Selection**: AnÃ¡lise de importÃ¢ncia, PCA, correlaÃ§Ã£o
3. **Model Selection**: Cross-validation, hyperparameter tuning
4. **Ensemble**: Stacking, voting, blending
5. **Validation**: Hold-out test set, mÃ©tricas de negÃ³cio

### Fase 3: Sistema de ProduÃ§Ã£o (2-3 semanas)

#### 3.1 API de ClassificaÃ§Ã£o
```python
# Endpoint de classificaÃ§Ã£o automÃ¡tica
POST /api/classify
{
    "image_path": "path/to/image.jpg",
    "return_confidence": true,
    "return_explanations": true
}

Response:
{
    "predicted_quality": 4,
    "confidence": 0.87,
    "predicted_issues": ["slight_blur"],
    "explanations": {
        "quality_factors": {
            "sharpness": 0.8,
            "exposure": 0.9,
            "composition": 0.7
        }
    },
    "needs_human_review": false
}
```

#### 3.2 Sistema de Feedback Loop
- **CorreÃ§Ãµes humanas** alimentam retreinamento
- **Monitoramento de drift** de dados
- **A/B testing** de modelos
- **MÃ©tricas de negÃ³cio** em tempo real

## ğŸ› ï¸ ImplementaÃ§Ã£o TÃ©cnica

### Dados Adicionais NecessÃ¡rios

#### 1. Schema Expandido do Banco de Dados
```sql
-- Tabela de features automÃ¡ticas
CREATE TABLE image_features (
    filename TEXT PRIMARY KEY,
    file_size INTEGER,
    width INTEGER,
    height INTEGER,
    format TEXT,
    
    -- EXIF data
    camera_make TEXT,
    camera_model TEXT,
    iso INTEGER,
    exposure_time REAL,
    f_number REAL,
    focal_length REAL,
    
    -- Computed features
    sharpness_score REAL,
    brightness_score REAL,
    contrast_score REAL,
    saturation_score REAL,
    noise_level REAL,
    
    -- Visual features (JSON)
    color_histogram TEXT,  -- JSON array
    texture_features TEXT, -- JSON object
    composition_score REAL,
    
    -- Deep learning embeddings
    cnn_features TEXT,     -- JSON array of embeddings
    
    extraction_timestamp TEXT
);

-- Tabela de prediÃ§Ãµes do modelo
CREATE TABLE ai_predictions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    filename TEXT,
    model_version TEXT,
    predicted_quality INTEGER,
    predicted_issues TEXT, -- JSON array
    confidence_score REAL,
    prediction_timestamp TEXT,
    
    -- Feedback loop
    human_correction TEXT,
    correction_timestamp TEXT,
    was_correct BOOLEAN
);

-- Tabela de performance do modelo
CREATE TABLE model_metrics (
    model_version TEXT,
    metric_name TEXT,
    metric_value REAL,
    evaluation_date TEXT,
    dataset_size INTEGER
);
```

#### 2. Pipeline de Feature Extraction
```python
class AdvancedFeatureExtractor:
    def extract_all_features(self, image_path):
        return {
            **self.extract_exif_features(image_path),
            **self.extract_visual_features(image_path),
            **self.extract_deep_features(image_path),
            **self.extract_composition_features(image_path)
        }
    
    def extract_visual_features(self, image_path):
        """Extrai features visuais tradicionais"""
        img = cv2.imread(image_path)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        return {
            'sharpness': self.calculate_sharpness(gray),
            'brightness': np.mean(gray),
            'contrast': np.std(gray),
            'noise_level': self.estimate_noise(gray),
            'color_histogram': self.extract_color_histogram(img),
            'texture_features': self.extract_texture_features(gray)
        }
```

### MÃ©tricas de AvaliaÃ§Ã£o

#### 1. MÃ©tricas TÃ©cnicas
- **Accuracy**: PrecisÃ£o geral do modelo
- **F1-Score**: Por classe (especialmente para classes minoritÃ¡rias)
- **Cohen's Kappa**: ConcordÃ¢ncia com rÃ³tulos humanos
- **AUC-ROC**: Para classificaÃ§Ã£o binÃ¡ria (boa/ruim)
- **Mean Absolute Error**: Para scores de qualidade

#### 2. MÃ©tricas de NegÃ³cio
- **Tempo de Rotulagem**: ReduÃ§Ã£o vs. processo manual
- **Throughput**: Imagens processadas por hora
- **Human-in-the-loop**: Taxa de casos que precisam revisÃ£o humana
- **Cost Savings**: ROI do sistema automatizado

## ğŸ“ˆ Roadmap de ImplementaÃ§Ã£o

### Semana 1-2: PreparaÃ§Ã£o
- [ ] Expandir schema do banco de dados
- [ ] Implementar feature extraction automÃ¡tica
- [ ] Configurar pipeline de coleta de dados
- [ ] Criar sistema de anotaÃ§Ã£o ativa

### Semana 3-4: Coleta de Dados
- [ ] Rotular 1000+ imagens com sistema melhorado
- [ ] Extrair features de todas as imagens
- [ ] Validar qualidade dos dados
- [ ] Implementar data augmentation

### Semana 5-6: Desenvolvimento do Modelo
- [ ] Treinar modelos baseline (RF, SVM)
- [ ] Implementar CNN com transfer learning
- [ ] Criar ensemble de modelos
- [ ] ValidaÃ§Ã£o cruzada e tuning

### Semana 7-8: Sistema de ProduÃ§Ã£o
- [ ] Implementar API de classificaÃ§Ã£o
- [ ] Integrar com interface web existente
- [ ] Sistema de monitoramento e feedback
- [ ] Testes A/B com usuÃ¡rios

### Semana 9-10: OtimizaÃ§Ã£o
- [ ] AnÃ¡lise de performance em produÃ§Ã£o
- [ ] Ajustes baseados em feedback real
- [ ] Implementar retreinamento automÃ¡tico
- [ ] DocumentaÃ§Ã£o e deploy final

## ğŸ’¡ PrÃ³ximos Passos Imediatos

1. **Expandir o banco de dados** com features automÃ¡ticas
2. **Implementar extraÃ§Ã£o de metadados** EXIF e features visuais
3. **Criar sistema de sugestÃµes** na interface web
4. **Coletar mais dados** com foco no balanceamento
5. **Desenvolver modelo baseline** com dados atuais + features

**Investimento estimado**: 10-12 semanas de desenvolvimento
**ROI esperado**: 70-80% de reduÃ§Ã£o no tempo de rotulagem manual
**Accuracy target**: 85%+ para classificaÃ§Ã£o de qualidade

---

*Este documento serÃ¡ atualizado conforme o progresso do projeto.*
